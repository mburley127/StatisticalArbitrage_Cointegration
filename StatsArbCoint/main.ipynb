{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Library Imports\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import itertools\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from statsmodels.tsa.stattools import adfuller\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  2 of 2 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date         XOM         CVX\n",
      "3769 2024-12-24  143.839996  106.400002\n",
      "3770 2024-12-26  143.979996  106.489998\n",
      "3771 2024-12-27  144.000000  106.480003\n",
      "3772 2024-12-30  143.070007  105.760002\n",
      "3773 2024-12-31  144.839996  107.570000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "### Function to Import Stock Data\n",
    "def import_stock_data(tickers, start_date, end_date):\n",
    "    data = pd.DataFrame()\n",
    "    if len([tickers]) == 1:\n",
    "        data[tickers] = yf.download(tickers, start_date, end_date)['Adj Close']\n",
    "        data = pd.DataFrame(data)\n",
    "    else:\n",
    "        for t in tickers:\n",
    "            data[t] = yf.download(tickers, start_date, end_date)['Adj Close']\n",
    "    \n",
    "    # Reset index to include the Date as a column\n",
    "    data = data.reset_index()\n",
    "\n",
    "    return data\n",
    "\n",
    "# Import Stock Data\n",
    "tickers = ['XOM', 'CVX']\n",
    "start_date = '2010-01-01'\n",
    "end_date = '2025-01-01'\n",
    "stock_data = import_stock_data(tickers, start_date, end_date)\n",
    "print(stock_data.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date       XOM       CVX\n",
      "0 2010-01-04  3.775075  3.670515\n",
      "1 2010-01-05  3.782133  3.674412\n",
      "2 2010-01-06  3.782258  3.683017\n",
      "3 2010-01-07  3.778484  3.679870\n",
      "4 2010-01-08  3.780248  3.675851\n"
     ]
    }
   ],
   "source": [
    "### Function to Compute Log Prices\n",
    "def compute_log_prices(data):\n",
    "    # Ensure 'Date' is present now\n",
    "    if 'Date' not in data.columns:\n",
    "        raise KeyError(\"The 'Date' column is missing from the DataFrame!\")\n",
    "\n",
    "    # Set Date as index and apply log transformation\n",
    "    data.set_index(\"Date\", inplace = True)\n",
    "    data = np.log(data)  # Apply log transformation\n",
    "\n",
    "    # Reset index to restore 'Date' as a column\n",
    "    data.reset_index(inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "log_prices = compute_log_prices(stock_data)\n",
    "print(log_prices.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -1.5074119144781142\n",
      "p-value: 0.529841636315544\n",
      "Series is non-stationary (fail to reject null hypothesis) and we can PROCEED with cointegration testing\n",
      "ADF Statistic: -1.179009107478344\n",
      "p-value: 0.6825596640695565\n",
      "Series is non-stationary (fail to reject null hypothesis) and we can PROCEED with cointegration testing\n"
     ]
    }
   ],
   "source": [
    "### ADF Test to check Stationarity\n",
    "def check_stationarity(series):\n",
    "    # ADF Test\n",
    "    result = adfuller(series)\n",
    "    print(f\"ADF Statistic: {result[0]}\")\n",
    "    print(f\"p-value: {result[1]}\")\n",
    "\n",
    "    if result[1] < 0.05:\n",
    "        print(\"Series is stationary (reject null hypothesis) and DO NOT test for cointegration\")\n",
    "    else:\n",
    "        print(\"Series is non-stationary (fail to reject null hypothesis) and we can PROCEED with cointegration testing\")\n",
    "\n",
    "# Check for each stock\n",
    "check_stationarity(log_prices[\"XOM\"])\n",
    "check_stationarity(log_prices[\"CVX\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check Cointegration\n",
    "''' \n",
    "The matrix Π determines whether the time series are cointegrated:\n",
    "    1. If Π has full rank (r = n), all series are stationary, no need for cointegration testing.\n",
    "    2. If Π has rank 0, no cointegration exists, meaning the series move independently.\n",
    "    3. If Π has reduced rank (0 < r < n), then there are r cointegrating relationships.\n",
    "'''\n",
    "def check_coint(data, r):\n",
    "    # n = number of columns (number of time series)\n",
    "    n = len(data.columns)\n",
    "    \n",
    "    # Case 1: No Cointegration\n",
    "    if r == 0:\n",
    "        print(f\"Since the matrix Π has rank 0 (r = {r}), the time series are likely non-stationary and no cointegration exists.\")\n",
    "    # Case 2: Some Cointegration Exists\n",
    "    elif 0 < r < n:\n",
    "        print(f\"Cointegration exists with {r} cointegrating relationships, meaning some assets share a long-term equilibrium.\")\n",
    "    # Case 3: Full Rank - All Series are Stationary\n",
    "    elif r == n:\n",
    "        print(f\"Since the matrix Π has full rank (r = {n}), all time series are stationary, so cointegration testing is unnecessary.\")\n",
    "    # Error Handling\n",
    "    else:\n",
    "        print(\"Test did not run successfully. Please check your input values.\")\n",
    "\n",
    "# Example Usage\n",
    "#check_coint(stock_data, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Johansen Test Results (det_order = 1)\n",
      "\n",
      "Trace Statistics: [15.44319622  2.19358082]\n",
      "Max Eigenvalue Statistics: [13.2496154   2.19358082]\n",
      "\n",
      "Critical Values (Trace Test):\n",
      "1%: [16.1619  2.7055], 5%: [18.3985  3.8415], 10%: [23.1485  6.6349]\n",
      "\n",
      "Critical Values (Max Eigenvalue Test):\n",
      "1%: [15.0006  2.7055], 5%: [17.1481  3.8415], 10%: [21.7465  6.6349]\n",
      "\n",
      "Estimated number of cointegrating relationships: 0\n",
      "Since the matrix Π has rank 0 (r = 0), the time series are likely non-stationary and no cointegration exists.\n"
     ]
    }
   ],
   "source": [
    "### Test Cointegration - Johansen Test\n",
    "''' \n",
    "The Johansen test is a statistical test used to determine the number of cointegrating relationships among multiple time series. \n",
    "The test uses Trace and Max Eigenvalue tests to check if a group of non-stationary time series share a stable, long-term equilibrium. \n",
    "If cointegration exists, the assets move together over time, making them suitable for pairs trading or statistical arbitrage.\n",
    "'''\n",
    "# https://medium.com/@cemalozturk/unveiling-cointegration-johansen-test-explained-with-python-examples-db8385219f1f\n",
    "def johansen_test(data, det_order = 0, k_ar_diff = 1):\n",
    "    \"\"\"\n",
    "    det_order (int): The order of deterministic terms.\n",
    "                     -1: No constant or trend.\n",
    "                      0: Constant term only.\n",
    "                      1: Constant and trend terms.\n",
    "    k_ar_diff (int): The number of lags to include in the VAR model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ensure Date column is removed if it exists\n",
    "        if 'Date' in data.columns:\n",
    "            data = data.drop(columns = ['Date'])\n",
    "\n",
    "        # Convert to NumPy array\n",
    "        data_np = data.values\n",
    "\n",
    "        # Run Johansen cointegration test\n",
    "        result = coint_johansen(data_np, det_order, k_ar_diff)\n",
    "        print(f'Johansen Test Results (det_order = {det_order})\\n')\n",
    "\n",
    "        # Print test statistics\n",
    "        trace_stats = result.lr1\n",
    "        max_eigenval_stats = result.lr2\n",
    "        print('Trace Statistics:', trace_stats)\n",
    "        print('Max Eigenvalue Statistics:', max_eigenval_stats)\n",
    "        \n",
    "        # Perform Trace Test and Max Eigenvalue Test at 1%, 5%, and 10% intervals\n",
    "        print('\\nCritical Values (Trace Test):')\n",
    "        print(f\"1%: {result.cvt[:, 0]}, 5%: {result.cvt[:, 1]}, 10%: {result.cvt[:, 2]}\")\n",
    "\n",
    "        print('\\nCritical Values (Max Eigenvalue Test):')\n",
    "        print(f\"1%: {result.cvm[:, 0]}, 5%: {result.cvm[:, 1]}, 10%: {result.cvm[:, 2]}\\n\")\n",
    "\n",
    "        # Determine the number of cointegrating relationships\n",
    "        rank_est = sum(result.lr1 > result.cvt[:, 1])  # Compare trace test stats to 5% critical values\n",
    "        print(f'Estimated number of cointegrating relationships: {rank_est}')\n",
    "\n",
    "        # Return Cointegration\n",
    "        check_coint(stock_data, rank_est)\n",
    "\n",
    "        return trace_stats, max_eigenval_stats, rank_est, result.cvt[:, 1], result.cvm[:, 1]\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'An error occurred during the Johansen test: {e}')\n",
    "        return None\n",
    "\n",
    "# Johansen Test Function Return \n",
    "trace_stats, max_eigenval_stats, rank_est, crit_vals_trace, crit_vals_max_ev = johansen_test(log_prices, det_order = 1, k_ar_diff = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Function to Compute P-Values and the Cointegration Score\n",
    "def pvalues_coint_scores(trace_stats, crit_vals_trace):\n",
    "    # Create empty array to store p-values and cointegration scores\n",
    "    p_values = []\n",
    "    coint_scores = []\n",
    "\n",
    "    # Iterate over trace stats by "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
